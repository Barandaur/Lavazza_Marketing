{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='top'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Personas and as-is Customer Journeys\n",
    "The foundation of our personas uses the analysis of Lavazza’s Twitter followers’ descriptions  as a building block, especially for Andrea and Arianna. Marta, instead, was framed relying on our personal knowledge and experience, as she is close to us, and on survey-like questions to the friends of ours that matched her main features. The specific characterizations are based on empathization, done on several data sources (mostly: internal material, other insights obtained through Twitter Api, readings of Amazon reviews of several coffee products) as well as by itself. For example, we can use Facebook ads creation to create a query combining interest for aperitif or coffee to being a universitary student 18-25 woman in Italy, thus obtaining music interests for one of our personas.\n",
    "\n",
    "\n",
    "Hereby we present three personas that we identified, and their as-is customer journeys. In a section 2.0, instead, we will try to figure out how these personas might interface with our product, thus building customer journeys for our kits.\n",
    "\n",
    "## Index\n",
    "\n",
    "##### Codes:\n",
    "\n",
    "\n",
    "- [Tf-idf on users description](#tf-idf)\n",
    "\n",
    "\n",
    "- [Pages liked by lavazza followers](#pages_liked)\n",
    "\n",
    "##### Personas:\n",
    "\n",
    "- [Arianna, the traveller](#Arianna)\n",
    "    > Description\n",
    "    >\n",
    "    > Customer Journey as-is\n",
    "    >\n",
    "    > Market size\n",
    "- [Andrea, the business man](#Andrea)\n",
    "    > Description\n",
    "    >\n",
    "    > Customer Journey as-is\n",
    "    >\n",
    "    > Market size\n",
    "- [Marta, the off-site student](#Marta)\n",
    "    > Description\n",
    "    >\n",
    "    > Customer Journey as-is\n",
    "    >\n",
    "    > Market size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'tf-idf'> </a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf on users descriptions\n",
    "\n",
    "In this section we use information retrieval on the descriptions of Lavazza's followers. Notably, after some pre-processing and cleaning, we use tf-idf, which is a technique that allows to filter out non-relevant information. Indeed, it returns only words (or, in better NLP language, tokens) that are very frequent in some descriptions but don't occur in most of the descriptions, otherwise they would be just noise.\n",
    "\n",
    "Given the preprocessing and given the nature and diversity of this dataset, running a tf-idf is a bit of an overkill, as we obtain the same information given by simply collecting term frequency; though we can easily obtain both at the same time, and it's extremely fast anyway, so there was no reason not to implement it.\n",
    "\n",
    "From the info obtained, we framed 2 of our personas: Andrea and Arianna. Notably, we will be able to see a clear interest in travelling, as well as a general background in business-related jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' loading db and libraries'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' loading db and libraries'''\n",
    "\n",
    "import sqlite3\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# path\n",
    "b_dir= r'C:/Users/Eugen/Documents/Uni/1 Marketing/API stuff' \n",
    "\n",
    "database_to_use = 'Brand_Followers.db'\n",
    "\n",
    "# connect to the db\n",
    "con = sqlite3.connect(database_to_use) \n",
    "cur = con.cursor()\n",
    "\n",
    "''' loading db and libraries'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_descriptions(page, con):\n",
    "    \n",
    "    \"\"\" Connects to the DB and extracts to a list the descriptions of specified page users.\"\"\"\n",
    "    \n",
    "    query=\"\"\"\n",
    "        SELECT description \n",
    "        FROM Users \n",
    "        WHERE twitter_page == '{}' \n",
    "        GROUP BY (user_id)  \n",
    "        \"\"\".format(page)  #querying like this solves duplication issues\n",
    "    \n",
    "    # Reads query and takes column 'descriptions' transforming it to a list\n",
    "    users_descriptions=pd.read_sql_query(query, con).description.to_list()\n",
    "    print(\"we have {} user descriptions\".format(len(users_descriptions))) # useless knowledge\n",
    "    \n",
    "    return users_descriptions\n",
    "\n",
    "\n",
    "def bruteforce_clean(l):\n",
    "    \n",
    "    \"\"\"keeps only words with latin letters ( --> no arab/idiograms/emojis)\n",
    "    through regular expressions and returns a list.\"\"\"\n",
    "    \n",
    "    # Strangely enough there are many hyperlinks to get rid of\n",
    "    descr=[re.sub(\"http\\S+\", '', d).lower() for d in l if d] \n",
    "    \n",
    "    # Keeps only these [a-zA-Z]\n",
    "    only_latin_letters=[re.sub('[^a-zA-Z]+', ' ',d) for d in descr if d]\n",
    "    \n",
    "    # Creates a set of stopwords (every language in NLTK library)\n",
    "    stopWords = set(stopwords.words())\n",
    "    \n",
    "    # Remove stopwords and lemmatize\n",
    "    #clean=[\" \".join([w.lemma_ for w in nlp(words) if w not in stopWords]) for words in only_latin_letters]\n",
    "    # Removes stopwords\n",
    "    clean=[\" \".join([w for w in words.split() if w not in stopWords]) for words in only_latin_letters]\n",
    "    print('We have {} non empty descriptions'.format(len(clean))) \n",
    "    \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract descriptions from Lavazza's followers \n",
    "page = \"lavazzagroup\"\n",
    "descr = extract_descriptions(page, con)\n",
    "descr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "clean=bruteforce_clean(descr)\n",
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigrams counts shape: (8809, 1344)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>coffee</td>\n",
       "      <td>504</td>\n",
       "      <td>4.067486</td>\n",
       "      <td>141.443068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>food</td>\n",
       "      <td>482</td>\n",
       "      <td>3.999143</td>\n",
       "      <td>119.594400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>love</td>\n",
       "      <td>357</td>\n",
       "      <td>4.324741</td>\n",
       "      <td>112.034737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>marketing</td>\n",
       "      <td>333</td>\n",
       "      <td>4.350301</td>\n",
       "      <td>97.579056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>life</td>\n",
       "      <td>265</td>\n",
       "      <td>4.558190</td>\n",
       "      <td>92.743586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>lover</td>\n",
       "      <td>232</td>\n",
       "      <td>4.671997</td>\n",
       "      <td>76.793141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>italian</td>\n",
       "      <td>236</td>\n",
       "      <td>4.717667</td>\n",
       "      <td>73.031784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>vita</td>\n",
       "      <td>145</td>\n",
       "      <td>5.149169</td>\n",
       "      <td>66.796730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>digital</td>\n",
       "      <td>193</td>\n",
       "      <td>4.841896</td>\n",
       "      <td>63.827335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>music</td>\n",
       "      <td>192</td>\n",
       "      <td>4.863287</td>\n",
       "      <td>62.756169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>manager</td>\n",
       "      <td>176</td>\n",
       "      <td>4.936148</td>\n",
       "      <td>60.938534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>italy</td>\n",
       "      <td>188</td>\n",
       "      <td>4.890686</td>\n",
       "      <td>59.987461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>mondo</td>\n",
       "      <td>147</td>\n",
       "      <td>5.113829</td>\n",
       "      <td>58.630567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>social</td>\n",
       "      <td>174</td>\n",
       "      <td>4.953744</td>\n",
       "      <td>56.621047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>media</td>\n",
       "      <td>184</td>\n",
       "      <td>4.918857</td>\n",
       "      <td>56.515392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>world</td>\n",
       "      <td>171</td>\n",
       "      <td>4.965649</td>\n",
       "      <td>56.398355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>business</td>\n",
       "      <td>181</td>\n",
       "      <td>4.965649</td>\n",
       "      <td>56.240660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>caf</td>\n",
       "      <td>115</td>\n",
       "      <td>5.448914</td>\n",
       "      <td>55.683720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>instagram</td>\n",
       "      <td>124</td>\n",
       "      <td>5.287852</td>\n",
       "      <td>55.654881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>travel</td>\n",
       "      <td>186</td>\n",
       "      <td>4.896257</td>\n",
       "      <td>54.724767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word   tf       idf       tfidf\n",
       "0      coffee  504  4.067486  141.443068\n",
       "1        food  482  3.999143  119.594400\n",
       "2        love  357  4.324741  112.034737\n",
       "3   marketing  333  4.350301   97.579056\n",
       "4        life  265  4.558190   92.743586\n",
       "5       lover  232  4.671997   76.793141\n",
       "6     italian  236  4.717667   73.031784\n",
       "7        vita  145  5.149169   66.796730\n",
       "8     digital  193  4.841896   63.827335\n",
       "9       music  192  4.863287   62.756169\n",
       "10    manager  176  4.936148   60.938534\n",
       "11      italy  188  4.890686   59.987461\n",
       "12      mondo  147  5.113829   58.630567\n",
       "13     social  174  4.953744   56.621047\n",
       "14      media  184  4.918857   56.515392\n",
       "15      world  171  4.965649   56.398355\n",
       "16   business  181  4.965649   56.240660\n",
       "17        caf  115  5.448914   55.683720\n",
       "18  instagram  124  5.287852   55.654881\n",
       "19     travel  186  4.896257   54.724767"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only uniigrams. Not setting laguages for vectorizers because we have many, only analyzing words\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word', min_df=0.001, max_df=0.9)\n",
    "\n",
    "X11 = vectorizer.fit_transform(clean)\n",
    "print(\"Unigrams counts shape: {}\".format(X11.shape))\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                                   min_df=0.001,\n",
    "                                   max_df=0.9,   \n",
    "                                   sublinear_tf=True) \n",
    "\n",
    "X12 = tfidf_vectorizer.fit_transform(clean)\n",
    "\n",
    "# sets up df\n",
    "df = pd.DataFrame(data={'word': vectorizer.get_feature_names(), \n",
    "                        'tf': X11.sum(axis=0).A1, \n",
    "                        'idf': tfidf_vectorizer.idf_,  \n",
    "                        'tfidf': X12.sum(axis=0).A1  \n",
    "                       })\n",
    "\n",
    "#sorting dataframe and showing\n",
    "df = df.sort_values(['tfidf', 'tf', 'idf'], ascending=False).reset_index(drop=True)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi-grams - Counts shape: (8809, 79)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>social media</td>\n",
       "      <td>96</td>\n",
       "      <td>5.519295</td>\n",
       "      <td>73.595681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>food wine</td>\n",
       "      <td>41</td>\n",
       "      <td>6.345973</td>\n",
       "      <td>33.547477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>digital marketing</td>\n",
       "      <td>36</td>\n",
       "      <td>6.472725</td>\n",
       "      <td>30.999132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>made italy</td>\n",
       "      <td>31</td>\n",
       "      <td>6.617907</td>\n",
       "      <td>29.723646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>co founder</td>\n",
       "      <td>29</td>\n",
       "      <td>6.751438</td>\n",
       "      <td>25.622600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>coffee lover</td>\n",
       "      <td>24</td>\n",
       "      <td>6.864767</td>\n",
       "      <td>23.395884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>official twitter</td>\n",
       "      <td>27</td>\n",
       "      <td>6.751438</td>\n",
       "      <td>22.453823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>food beverage</td>\n",
       "      <td>20</td>\n",
       "      <td>7.039120</td>\n",
       "      <td>19.087723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>food travel</td>\n",
       "      <td>21</td>\n",
       "      <td>6.992600</td>\n",
       "      <td>17.558621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>italian food</td>\n",
       "      <td>19</td>\n",
       "      <td>7.087910</td>\n",
       "      <td>17.389676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>marketing comunicazione</td>\n",
       "      <td>18</td>\n",
       "      <td>7.139204</td>\n",
       "      <td>16.977523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>follow us</td>\n",
       "      <td>18</td>\n",
       "      <td>7.139204</td>\n",
       "      <td>16.699168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>part time</td>\n",
       "      <td>20</td>\n",
       "      <td>7.087910</td>\n",
       "      <td>16.095867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>project manager</td>\n",
       "      <td>17</td>\n",
       "      <td>7.193271</td>\n",
       "      <td>15.380867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>graphic designer</td>\n",
       "      <td>17</td>\n",
       "      <td>7.250429</td>\n",
       "      <td>15.021622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>good food</td>\n",
       "      <td>16</td>\n",
       "      <td>7.250429</td>\n",
       "      <td>14.949679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>full time</td>\n",
       "      <td>18</td>\n",
       "      <td>7.139204</td>\n",
       "      <td>14.835941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>marketing communication</td>\n",
       "      <td>16</td>\n",
       "      <td>7.250429</td>\n",
       "      <td>14.294770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>food blogger</td>\n",
       "      <td>15</td>\n",
       "      <td>7.311054</td>\n",
       "      <td>14.127910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>husband father</td>\n",
       "      <td>15</td>\n",
       "      <td>7.311054</td>\n",
       "      <td>14.091151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       word  tf       idf      tfidf\n",
       "0              social media  96  5.519295  73.595681\n",
       "1                 food wine  41  6.345973  33.547477\n",
       "2         digital marketing  36  6.472725  30.999132\n",
       "3                made italy  31  6.617907  29.723646\n",
       "4                co founder  29  6.751438  25.622600\n",
       "5              coffee lover  24  6.864767  23.395884\n",
       "6          official twitter  27  6.751438  22.453823\n",
       "7             food beverage  20  7.039120  19.087723\n",
       "8               food travel  21  6.992600  17.558621\n",
       "9              italian food  19  7.087910  17.389676\n",
       "10  marketing comunicazione  18  7.139204  16.977523\n",
       "11                follow us  18  7.139204  16.699168\n",
       "12                part time  20  7.087910  16.095867\n",
       "13          project manager  17  7.193271  15.380867\n",
       "14         graphic designer  17  7.250429  15.021622\n",
       "15                good food  16  7.250429  14.949679\n",
       "16                full time  18  7.139204  14.835941\n",
       "17  marketing communication  16  7.250429  14.294770\n",
       "18             food blogger  15  7.311054  14.127910\n",
       "19           husband father  15  7.311054  14.091151"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only bigrams. Not setting laguages for vectorizers because we have many, only analyzing words\n",
    "vectorizer2 = CountVectorizer(analyzer='word', min_df=0.001, max_df=0.8, ngram_range=(2,2))\n",
    "\n",
    "X21 = vectorizer2.fit_transform(clean) # Counts\n",
    "\n",
    "print(\"Bi-grams - Counts shape: {}\".format(X21.shape))\n",
    "\n",
    "tfidf_vectorizer_2 = TfidfVectorizer(analyzer='word',  \n",
    "                                   min_df=0.001,  \n",
    "                                   max_df=0.8,   \n",
    "                                   sublinear_tf=True,\n",
    "                                   ngram_range=(2,2))  \n",
    "\n",
    "X22 = tfidf_vectorizer_2.fit_transform(clean) #tfidf \n",
    "\n",
    "# sets up df\n",
    "df2 = pd.DataFrame(data={'word': vectorizer2.get_feature_names(), \n",
    "                        'tf': X21.sum(axis=0).A1,  \n",
    "                        'idf': tfidf_vectorizer_2.idf_,  #idf\n",
    "                        'tfidf': X22.sum(axis=0).A1 \n",
    "                       })\n",
    "\n",
    "#sorting dataframe and showing\n",
    "df2 = df2.sort_values(['tfidf', 'tf', 'idf'], ascending=False).reset_index(drop=True)\n",
    "df2.head(20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='pages_liked'></a>\n",
    "## Liked pages\n",
    "\n",
    "- [back on top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def common_pages(df, page, n):\n",
    "    \n",
    "    \"\"\"Inputs:\n",
    "    -\"page\" of interest (eg 'lavazzagroup'), \n",
    "    -\"n\" most liked pages for the queried page users \n",
    "    - \"con\" connection to DB\n",
    "    through regular expressions splits-extracts pages.\n",
    "    returns a distionary with the n most common pages counts\"\"\"\n",
    "    \n",
    "    users_likes_list=df.pages_liked.to_list() #transform to list\n",
    "    \n",
    "    #for each user (with not empty pages_like field) we create a list where every element is a liked page [list of list of string]\n",
    "    liked_reed= [user_likes.split(\" _***_ \") for user_likes in users_likes_list if user_likes] \n",
    "    print(f\"We have {len(liked_reed)} users with pages likes in '{page}'.\\n\") #how many users were not empty\n",
    "    \n",
    "    #instance counter and counts\n",
    "    cnt=Counter()\n",
    "    for i in liked_reed:\n",
    "        cnt.update(i)\n",
    "        \n",
    "    return cnt.most_common(n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 13984 users with pages likes in 'lavazzagroup'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('lavazzagroup', 13775),\n",
       " ('BarackObama', 4363),\n",
       " ('YouTube', 3523),\n",
       " ('repubblica', 3410),\n",
       " ('nytimes', 3394),\n",
       " ('Twitter', 3368),\n",
       " ('Corriere', 3222),\n",
       " ('Pontifex_it', 3191),\n",
       " ('SkyTG24', 3056),\n",
       " ('matteorenzi', 2852),\n",
       " ('lorenzojova', 2821),\n",
       " ('LaStampa', 2761),\n",
       " ('sole24ore', 2757),\n",
       " ('Agenzia_Ansa', 2627),\n",
       " ('Expo2015Milano', 2626),\n",
       " ('fattoquotidiano', 2454),\n",
       " ('CNN', 2446),\n",
       " ('BBCBreaking', 2442),\n",
       " ('BillGates', 2359),\n",
       " ('realDonaldTrump', 2315),\n",
       " ('instagram', 2315),\n",
       " ('RaiNews', 2312),\n",
       " ('ValeYellow46', 2300),\n",
       " ('radiodeejay', 2300),\n",
       " ('Fiorello', 2295),\n",
       " ('cnnbrk', 2290),\n",
       " ('redazioneiene', 2250),\n",
       " ('BBCWorld', 2233),\n",
       " ('TheEconomist', 2223),\n",
       " ('Google', 2213),\n",
       " ('Internazionale', 2206),\n",
       " ('NASA', 2169),\n",
       " ('robertosaviano', 2117),\n",
       " ('katyperry', 2113),\n",
       " ('WSJ', 2112),\n",
       " ('NicoSavi', 2023),\n",
       " ('reportrai3', 2010),\n",
       " ('NatGeo', 2007),\n",
       " ('ladygaga', 1990),\n",
       " ('Starbucks', 1980),\n",
       " ('illyIT', 1979),\n",
       " ('ilpost', 1972),\n",
       " ('dolcegabbana', 1946),\n",
       " ('Reuters', 1902),\n",
       " ('beppesevergnini', 1895),\n",
       " ('rihanna', 1888),\n",
       " ('POTUS', 1887),\n",
       " ('MediasetTgcom24', 1887),\n",
       " ('jtimberlake', 1850),\n",
       " ('La7tv', 1850)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = 'lavazzagroup'\n",
    "\n",
    "query=\"\"\"\n",
    "SELECT pages_liked, description \n",
    "FROM Users \n",
    "WHERE twitter_page == '{}' \n",
    "GROUP BY user_id \"\"\".format(page)  #querying that solves eventual duplicate ids issues\n",
    "df = pd.read_sql_query(query, con)\n",
    "\n",
    "\n",
    "lavazza = common_pages(df, page, 50)\n",
    "lavazza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have constructed a somewhat slow function will\n",
    "# allow us to get the most liked pages by a subset\n",
    "# of Lavazza's followers who have certain words\n",
    "# in their description, to better characterize and \n",
    "# understand our personas\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "df2 = df[df.notnull()][\"description\"]\n",
    "\n",
    "def filter_descriptions(df2, word1, word2, word3):\n",
    "    i = 0\n",
    "    l = []\n",
    "    for description in df2.to_numpy():\n",
    "        for word in nlp(str(description)):\n",
    "            if word1 in word.lemma_.lower() or word2 in word.lemma_.lower() or word2 in word.lemma_.lower(): \n",
    "                l.append(i)\n",
    "        i += 1\n",
    "    print(len(l))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402\n",
      "We have 401 users with pages likes in 'lavazzagroup'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('lavazzagroup', 382),\n",
       " ('BarackObama', 142),\n",
       " ('nytimes', 140),\n",
       " ('lonelyplanet', 132),\n",
       " ('Twitter', 111),\n",
       " ('repubblica', 105),\n",
       " ('BBCBreaking', 104),\n",
       " ('NatGeo', 104),\n",
       " ('instagram', 103),\n",
       " ('Expo2015Milano', 102),\n",
       " ('CNN', 101),\n",
       " ('BBCWorld', 99),\n",
       " ('SlowFoodItaly', 97),\n",
       " ('YouTube', 97),\n",
       " ('Corriere', 97),\n",
       " ('TripAdvisor', 96),\n",
       " ('CNTraveler', 93),\n",
       " ('TravelLeisure', 92),\n",
       " ('cnnbrk', 91),\n",
       " ('Starbucks', 87),\n",
       " ('lorenzojova', 86),\n",
       " ('WSJ', 85),\n",
       " ('NatGeoTravel', 83),\n",
       " ('TIME', 83),\n",
       " ('SkyTG24', 83),\n",
       " ('HuffPost', 83),\n",
       " ('NewYorker', 82),\n",
       " ('TheEconomist', 82),\n",
       " ('Forbes', 82),\n",
       " ('Google', 82),\n",
       " ('Pontifex_it', 82),\n",
       " ('ilpost', 81),\n",
       " ('katyperry', 81),\n",
       " ('TheEllenShow', 80),\n",
       " ('lonelyplanet_it', 80),\n",
       " ('cntraveller', 80),\n",
       " ('jamieoliver', 79),\n",
       " ('LaStampa', 79),\n",
       " ('foodandwine', 78),\n",
       " ('viaggiatori', 78),\n",
       " ('wireditalia', 77),\n",
       " ('Alitalia', 77),\n",
       " ('ilGamberoRosso', 76),\n",
       " ('Internazionale', 76),\n",
       " ('Agenzia_Ansa', 76),\n",
       " ('Italia', 75),\n",
       " ('BillGates', 75),\n",
       " ('sole24ore', 75),\n",
       " ('Reuters', 74),\n",
       " ('luxury__travel', 74)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = filter_descriptions(df2, \"travel\", \"viaggi\", \"viaggiare\")\n",
    "df3 = df.loc[l]\n",
    "common_pages(df3, page, 50)\n",
    "\n",
    "# considering only Lavazza's followers who have travel related\n",
    "# words in their descriptions, we notice 2 particularly \n",
    "# interesting results: about 1 on 4 likes TravelLeisure and/or\n",
    "# luxury__travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548\n",
      "We have 547 users with pages likes in 'lavazzagroup'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('lavazzagroup', 536),\n",
       " ('BarackObama', 227),\n",
       " ('repubblica', 193),\n",
       " ('nytimes', 184),\n",
       " ('sole24ore', 179),\n",
       " ('Twitter', 171),\n",
       " ('wireditalia', 167),\n",
       " ('Corriere', 164),\n",
       " ('YouTube', 161),\n",
       " ('Google', 159),\n",
       " ('ninjamarketing', 152),\n",
       " ('Forbes', 152),\n",
       " ('WIRED', 148),\n",
       " ('Internazionale', 148),\n",
       " ('Expo2015Milano', 147),\n",
       " ('SkyTG24', 146),\n",
       " ('matteorenzi', 145),\n",
       " ('instagram', 145),\n",
       " ('TheEconomist', 142),\n",
       " ('BillGates', 141),\n",
       " ('LaStampa', 137),\n",
       " ('spinozait', 135),\n",
       " ('mashable', 135),\n",
       " ('Agenzia_Ansa', 135),\n",
       " ('Pontifex_it', 133),\n",
       " ('fattoquotidiano', 131),\n",
       " ('BBCBreaking', 130),\n",
       " ('WSJ', 128),\n",
       " ('skande', 128),\n",
       " ('CNN', 126),\n",
       " ('TechCrunch', 126),\n",
       " ('hootsuite', 124),\n",
       " ('BBCWorld', 120),\n",
       " ('startup_italia', 119),\n",
       " ('Starbucks', 118),\n",
       " ('lorenzojova', 116),\n",
       " ('RiccardoLuna', 115),\n",
       " ('TIME', 114),\n",
       " ('Barilla', 114),\n",
       " ('SlowFoodItaly', 113),\n",
       " ('TEDTalks', 112),\n",
       " ('beppesevergnini', 112),\n",
       " ('RudyBandiera', 108),\n",
       " ('cnnbrk', 106),\n",
       " ('LinkedIn', 105),\n",
       " ('Reuters', 104),\n",
       " ('richardbranson', 104),\n",
       " ('realDonaldTrump', 103),\n",
       " ('guardian', 103),\n",
       " ('ilpost', 103)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = filter_descriptions(df2, \"marketing\", \"manager\", \"business\")\n",
    "df3 = df.loc[l]\n",
    "common_pages(df3, page, 50)\n",
    "\n",
    "# considering business related folks.\n",
    "# Some highlights include Expo2015Milano, spinozait, mashable, \n",
    "# TEDTalks, TechCrunch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='Arianna'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = #00B0F0 > Arianna, the traveller \n",
    "[Back on top](#top)\n",
    " \n",
    "## <font color = #00B0F0 >  1.1\t Arianna’s description \n",
    "Personal description:\n",
    "- Citizen of the world\n",
    "-\tStudent and/or worker, usually engaged in several activities, whether they are for fun, for helping out others or to earn money for future travels\n",
    "-\tLives in the present, but she likes to watch photos and remember past experiences as much as she likes to plan her future travels\n",
    "-\tGets easily bored if alone and/or has nothing to do\n",
    "-\tCurios, open minded, always on the lookout for new experiences\n",
    "-\tShares her day-to-day life on Facebook and/or Instagram\n",
    "- She likes food and drinks\n",
    "\n",
    "\n",
    "Travelling traits (These were identified also thanks to the work of [(Park et al., 2010)](https://www.researchgate.net/publication/232823986_Travel_Personae_of_American_Pleasure_Travelers_A_Network_Analysis), drawing the relevant combination that fitted to Arianna’s description, while keeping in mind that the study referred to the American market):\n",
    "-\tAll Arounder\n",
    "-\tSight Seeker\n",
    "-   Food Traveller\n",
    "\n",
    "\n",
    "Arianna as a coffee consumer:\n",
    "-\tCoffee is a perfect match to her life-enthusiast personality, energic and positive\n",
    "-\tHas a 360° appreciation for coffee\n",
    "-\tCoffee helps her ushering in an eventful day, while it is a social moment in the afternoon\n",
    "-\tCoffee helps her to get the most out of travels\n",
    "-\tShe likes good coffee taste, but she’s used to adapting\n",
    "\n",
    "\n",
    "\n",
    "Note: our analysis above showed that about 1 out of 4 of travellers who follow Lavazza are particularly interested in luxury. here we described a more general version of this persona, that can account also for the other travellers, but it will be important to keep in mind that a wealthier and more luxury oriented specification of this persona exists, among Lavazza's fanbase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = #00B0F0 > 1.2\tArianna’s Customer Journey as-is\n",
    "We identified 2 relevant customer journeys for this persona, as she has different needs and pain-points when she travels compared to when she drinks coffee during her normal days. \n",
    "    \n",
    "    \n",
    "*Arianna day to day customer journey:*\n",
    "\n",
    "\n",
    "Arianna’s use of coffee is guided by different drivers, but let’s start with the moment of purchase. Her user need in this case is, obviously, refilling her coffee powder stocks. To achieve this, she will take one of the following routes:\n",
    "\n",
    "\n",
    "- **Supermarket**, she usually buys it here, since it’s more convenient, as she can buy it together with her usual grocery shopping. Sometimes, though, she can lose track of some things, leading to pain points, for example having to walk to the supermarket if she’s out of stock, or, possibly, having to renounce at it altogether. Usually, walking by itself isn’t a problem for a person like her, but having to do so for a contingency certainly isn’t appealing. An opportunity to address these pain points is an app/service which, using localization and other data, reminds her to buy coffee powder when at the supermarket and almost out of powder. Of course she may not like the idea of being ‘tracked’, so it would work better if it just pops out a reminder when she is likely to have finished her previously purchased coffee powder.\n",
    "- **Online**,   buying online can potentially save her time, allow her to choose better and among more alternatives, and it can be more convenient as well. There are a lot of potential pain points though, for example there are longer timings involved she needs to be home when it is being delivered, there are expedition fees which can be annoying, as she might consider them as ‘wasted’ money, but there are also problems with setting the threshold for a free delivery or setting offers in general . Finally, she has some environmental sensitivity, so she may be bothered by excessive delivery packaging. As for the opportunities in this step, one needs to be careful with the offers and the free expedition thresholds, on top of sticking to essential packaging, possibly having cardboard of the right dimensions for most orders.\n",
    "\n",
    "As for her use of coffee, we distinguish among 4 main potential moments:\n",
    "-\t**Morning**, she consumes coffee as part of her morning ritual, to kickstart her day. She may need to wake up early to be able to prepare it while being on time, something which she cares a lot about. An opportunity here would be to have her use a machine or prepare it the day before and keep it warm\n",
    "-\t**Afternoon 1/2**, she uses coffee after eating, as a pleasure and a habit. Analysing Lavazza internal data and focusing on the Italian market, we can see that 24% of people interviewed in a survey conducted in 2016 drank coffee in the afternoon. In particular, consumers reported drinking coffee during this time of the day for several reasons: \n",
    "    *\tthey want a boost of energy\n",
    "    *\tthey want to take a break\n",
    "    *\tit is a habit\n",
    "    *\tthey want to relax\n",
    "    *\tthey want to spend quality time together with other people\n",
    "-\t**Afternoon 2/2**, she may take this coffee to relax, before resuming to her activity or switching to another one. Pain points include the fact that she may want to spend more time with this relaxing ritual, plus, after a bit, it can get old for a curios persona like her.\n",
    "This goes without saying that it may be the 3d or 4th coffee of the day, so it can start to get unhealthy. \n",
    "Opportunities include the ideation of a product which combines coffee with novelty and a longer, more active ritual, while possibly reducing the coffee intake for this moment Drinks coffee after dinner, if she has to work 'til late\n",
    "-\t**Evening**, she may consume coffee if she has to work ‘till late, although there is the obvious pain point given by the fact that it interferes with her sleep\n",
    "\n",
    "\n",
    "*Arianna customer journey during travel:*\n",
    "\n",
    "Here she may want to taste a decent coffee product that helps her to reach the right mood and get the most out of otherwise filler moments. Often, coffee lovers can’t resist the urge of having a coffee, even while flying, despite it being of extremely low quality. Furthermore, an active persona as our Arianna is easily offset by unavoidable waiting times, resorting to social media self-amusement which quickly leads to boredom anyway. We will propose the customer journey for this scenario in a more compact way:\n",
    "\n",
    " During travel |<font color = #ED7D31 > Morning      | <font color = #ED7D31 >Before departure | <font color = #ED7D31 >During flight\n",
    "--|:---------:|:-----------:|:----------:\n",
    "<font color = #538135> User needs      |<font color = #538135> Wake up time may be pretty early, coffee to get in the mood |  <font color = #538135> Coffee to ease the pain of waiting  | <font color = #538135>Coffee to help time pass or to enjoy more the travelling moment\n",
    "<font color = #FF0000>Pain points   | <font color = #FF0000>Need to wake up even earlier | <font color = #FF0000>Bad quality coffees if bought in-place |<font color = #FF0000> Bad tasting and costly coffees if bought in-place (e.g. due to the [bad water](https://www.thrillist.com/travel/nation/why-airplane-coffee-is-bad) in the airplane case )\n",
    "<font color = #2F5496>Opportunities  | <font color = #2F5496>High quality coffee machines, to combine taste and speed | <font color = #2F5496>[Travel mugs](https://www.goodhousekeeping.com/travel-products/travel-coffee-mug-reviews/g785/best-travel-coffee-mugs/) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = #00B0F0 > 1.3\tArianna’s Market size\n",
    "    \n",
    "*In order to estimate market sizes for our personas, we will bring up two or more estimates: some are broader and consider only quintessential characteristics of our personas, while the others restricts the market to people who are really similar to our pictured persona*\n",
    "\n",
    "Considering 18-35 y.o. italian speakers living in Italy, who are who are frequent travellers and travel frequently abroad, interested in coffee, cocktails and airplane travels, we get an estimate of 360.000 people.\n",
    "If we restrict also to those who have had a mobile device for more than 19 months, and who use Facebook via mobile device (this means that they are more likely to share photos taken with the smartphone on social media, being accustomed to its use on a mobile device), we get a market size estimate of 180.000 people. \n",
    "Restricting to women, 20-30 y.o., with interest in Glamour, we get an estimate of 36.000 people, while further restricting to interests in 'sweets' and 'handmade' brings the number down to 5.700.\n",
    "\n",
    "While we used Facebook Api to get these results, one can obtain them from the [Facebook ads campaign section](https://www.facebook.com/adsmanager/creation?act=235630865#) as well. It suffices to [login](https://www.facebook.com/ads/audience-insights/people?act=264885008&age=18-&country=US), click on audience insights on the top left of the page, click on insertions, create an insertion using a campaign (which one can create on the fly), click on 'use an existing campaign', and with a couple more simple steps one can comfortably get a numerical estimate of the people who have certain behavours or interests. We still deemed important to be able to use the api, though. Indeed, as BA students, we need to be able to get results by coding. In particular, we created a function that, given some characteristics of the target users such as gender, age, interests, location and behaviors, returns the number of people corresponding to those characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'credentials'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d19b50951342>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m '''\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcredentials\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mApp_ID\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mApp_Secret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAccess_Token\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAd_Account_num\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfacebook_business\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFacebookAdsApi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfacebook_business\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madobjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaccount\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdAccount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'credentials'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Before importing the libraries, it is needed to update 2 scripts (adset.py and campaign.py).\n",
    "\n",
    "In particular, to update the first script go to the following page and copy the entire script:\n",
    "- https://github.com/facebook/facebook-python-business-sdk/blob/master/facebook_business/adobjects/adset.py\n",
    "Then, using jupyter, go to the Anaconda3/Lib/site-packages/facebookads/adobjects folder \n",
    "and find the adset.py script. Open it, paste the one you copied from github and save it. \n",
    "\n",
    "The same procedure must be done for the campaign.py script.\n",
    "- https://github.com/facebook/facebook-python-business-sdk/blob/master/facebook_business/adobjects/campaign.py \n",
    "\n",
    "It is also needed to have the script credentials.py containing\n",
    "one's App ID, App Secret, personal Access Token and the ad account number \n",
    "in the same folder as this notebook\n",
    "\n",
    "It's best to use the 'run' command instead of ctrl + enter, to quickly get\n",
    "to the end of this very long cell\n",
    "'''\n",
    "\n",
    "from credentials import App_ID,App_Secret,Access_Token,Ad_Account_num\n",
    "from facebook_business.api import FacebookAdsApi\n",
    "from facebook_business.adobjects.adaccount import AdAccount\n",
    "from facebook_business import adobjects\n",
    "from facebook_business.adobjects.targetingsearch import TargetingSearch\n",
    "from facebookads.adobjects.adset import AdSet\n",
    "from facebookads.adobjects.campaign import Campaign\n",
    "from facebook_business.adobjects.adaccount import AdAccount\n",
    "from facebook_business.adobjects.adaccountdeliveryestimate import AdAccountDeliveryEstimate\n",
    "from facebook_business.adobjects.adaccount import AdAccount\n",
    "from facebook_business.adobjects.adaccountdeliveryestimate import AdAccountDeliveryEstimate\n",
    "\n",
    "# connect\n",
    "FacebookAdsApi.init(app_id=App_ID,app_secret=App_Secret,access_token=Access_Token)\n",
    "my_account = AdAccount(Ad_Account_num)\n",
    "#print (my_account)\n",
    "\n",
    "#We can retrieve the potential size of a market from the estimated reach of a virtual ad campaign. \n",
    "#We can select several characteristics of the target audience we want to select, \n",
    "#such as location, age, relationship_statuses, life_events, interests and so on\n",
    "\n",
    "def get_country_code(country):\n",
    "    \n",
    "    \"\"\"\n",
    "    returns a list containing the country code\n",
    "    \"\"\"\n",
    "    if country == None:\n",
    "        return None\n",
    "    params = {\n",
    "        'q': country,\n",
    "        'type': 'adgeolocation',\n",
    "        'location_types': ['country'],\n",
    "    }\n",
    "    \n",
    "    # get the response\n",
    "    resp = TargetingSearch.search(params=params)\n",
    "    \n",
    "    # get the country code\n",
    "    country_code = resp[0]['country_code']\n",
    "    \n",
    "    return [country_code]\n",
    "\n",
    "def get_regions_id(regions_list:list):\n",
    "    \"\"\"\n",
    "    Regions is a list containing the names of the regions you are interested in, use a list even if you want to select\n",
    "    a single region. \n",
    "    \n",
    "    A maximum of 200 regions can be provided to the function\n",
    "    \n",
    "    returns a dictionary containin gthe key and the name of the regions selected\n",
    "    \n",
    "    \"\"\"\n",
    "    if regions_list == None:\n",
    "        return None\n",
    "    #create an empty dictionary which will contain the final output \n",
    "    output = {}\n",
    "    res_list = []\n",
    "\n",
    "    for reg in regions_list:\n",
    "        params = {\n",
    "        'q': reg,\n",
    "        'type': 'adgeolocation',\n",
    "        'location_types': ['region'],\n",
    "        }\n",
    "\n",
    "        resp = TargetingSearch.search(params=params)\n",
    "\n",
    "        # select the firts element in the list resp\n",
    "        d = resp[0]\n",
    "        \n",
    "        # keep only the id and the name of the region\n",
    "        keys = [\"key\", \"name\", 'country_code']\n",
    "        result = { k: d[k] for k in keys}\n",
    "\n",
    "        res_list.append(result)\n",
    "#         print(result)\n",
    "#         print()\n",
    "        \n",
    "    output['regions'] = res_list\n",
    "    #return output\n",
    "    return res_list\n",
    "    \n",
    "    \n",
    "def get_cities_id(cities_list:list, radius = 10, distance_unit = 'kilometer'):\n",
    "    \"\"\"\n",
    "    cities is a list containing the names of the cities you are interested in, use a list even if you want to select\n",
    "    a single city\n",
    "    \n",
    "    radius selects the distance from the city you want to include\n",
    "    \n",
    "    distance_unit is set to default to km, the other option is 'mile'\n",
    "    \n",
    "    returns a dictionary containing the key and the name of the cities selected\n",
    "    \n",
    "    \"\"\"\n",
    "    if cities_list == None:\n",
    "        return None\n",
    "    #create an empty dictionary which will contain the final output \n",
    "    output = {}\n",
    "    res_list = []\n",
    "\n",
    "    for city in cities_list:\n",
    "        params = {\n",
    "        'q': city,\n",
    "        'type': 'adgeolocation',\n",
    "        'location_types': ['city'],\n",
    "        }\n",
    "\n",
    "        resp = TargetingSearch.search(params=params)\n",
    "\n",
    "        # select the firts element in the list resp\n",
    "        d = resp[0]\n",
    "\n",
    "        keys = [\"key\", \"name\", 'country_code', \"region\", 'region_id']\n",
    "        result = { k: d[k] for k in keys}\n",
    "\n",
    "        res_list.append(result)\n",
    "#         print(result)\n",
    "#         print()\n",
    "        \n",
    "    output['cities'] = res_list\n",
    "    #return output\n",
    "    return res_list\n",
    "    \n",
    "    \n",
    "def regions_in_same_country(country:str, regions_list:list):\n",
    "    \"\"\"\n",
    "    returns true if all regions in regions_list are in the same country\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the country_code\n",
    "    country_code = get_country_code(country)[0]\n",
    "    \n",
    "    # get all the info regarding the regions\n",
    "    regions = get_regions_id(regions_list)\n",
    "    \n",
    "    for r in regions:\n",
    "        if r['country_code'] == country_code:\n",
    "            pass\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    # if it exit the for loop it means that all the regions belong to the same country    \n",
    "    return True\n",
    "\n",
    "def cities_in_same_country(country:str, cities_list:list):\n",
    "    \"\"\"\n",
    "    returns true if all the cities in cities_list are in the same country\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the country_code\n",
    "    country_code = get_country_code(country)[0]\n",
    "    \n",
    "    # get all the info regarding the cities\n",
    "    cities = get_cities_id(cities_list)\n",
    "    \n",
    "    for c in cities:\n",
    "        if c['country_code'] == country_code:\n",
    "            pass\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "def cities_in_same_regions(regions_list, cities_list):\n",
    "    \"\"\"\n",
    "    returns true if all the cities in cities_list are in at least one of the regions\n",
    "    \"\"\"\n",
    "    \n",
    "    # get all the info regarding the regions\n",
    "    regions = get_regions_id(regions_list)\n",
    "    \n",
    "    # get all the info regarding the cities\n",
    "    cities = get_cities_id(cities_list)\n",
    "    \n",
    "    # get a set of all the regions from cities\n",
    "    regions_from_cities = set()\n",
    "    for c in cities:\n",
    "        regions_from_cities.add(c['region'])\n",
    "        \n",
    "    # get a set of all the regions from regions\n",
    "    regions_from_regions = set(regions_list)\n",
    "    \n",
    "    if regions_from_cities == regions_from_regions:\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def extra_regions(regions_list, cities_list):\n",
    "    \"\"\"\n",
    "    returns the regions that do not contain any city from cities_list\n",
    "    \"\"\"\n",
    "    \n",
    "    # get all the info regarding the regions\n",
    "    regions = get_regions_id(regions_list)\n",
    "    \n",
    "    # get all the info regarding the cities\n",
    "    cities = get_cities_id(cities_list)\n",
    "    \n",
    "    # get a set of all the regions from cities\n",
    "    regions_from_cities = set()\n",
    "    for c in cities:\n",
    "        regions_from_cities.add(c['region'])\n",
    "        \n",
    "    # get a set of all the regions from regions\n",
    "    regions_from_regions = set(regions_list)\n",
    "    \n",
    "    # keep the regions that do not contain any city\n",
    "    regions_keep = regions_from_regions - regions_from_cities\n",
    "    \n",
    "    return list(regions_keep)\n",
    "\n",
    "def extra_cities(regions_list, cities_list):\n",
    "    \"\"\"\n",
    "    returns the cities that are not contained in any of the regions from regions_list\n",
    "    \"\"\"\n",
    "    \n",
    "    # get all the info regarding the regions\n",
    "    regions = get_regions_id(regions_list)\n",
    "    \n",
    "    # get all the info regarding the cities\n",
    "    cities = get_cities_id(cities_list)\n",
    "    \n",
    "    # get a set of all the regions from cities\n",
    "    cities_keep = []\n",
    "    regions_from_cities = set()\n",
    "    for c in cities:\n",
    "        \n",
    "        if c['region'] not in set(regions_list):\n",
    "            cities_keep.append(c['name'])\n",
    "    \n",
    "    return cities_keep\n",
    "\n",
    "def combine_geo_locations(country:str, regions_list:list, cities_list:list):\n",
    "    \n",
    "    \"\"\"\n",
    "    combines the results of get_country_code, get_regions_id and get_cities_id in order to avoid overlaps\n",
    "    IMPORTANT in the case of an overlap, the smaller of the 3 will be considered \n",
    "    \"\"\"\n",
    "    # if all the arguments are none, return none\n",
    "    if (country == None) and (regions_list == None) and (cities_list == None):\n",
    "        return None\n",
    "    \n",
    "    # regions if all the regions are within the country selected and cities_list is None,\n",
    "    # cities if all the cities are within the regions_list\n",
    "    output = {}\n",
    "    \n",
    "    if (country == None) and (regions_list != None) and (cities_list == None):\n",
    "        output['regions'] = get_regions_id(regions_list)\n",
    "        return output\n",
    "    \n",
    "    if (country == None) and (regions_list == None) and (cities_list != None):\n",
    "        output['cities'] = get_cities_id(cities_list)\n",
    "        return output\n",
    "    \n",
    "    # the output need to be a dictonary with key countries if both regions_list and cities_list are None\n",
    "    if (regions_list == None) and (cities_list == None):\n",
    "        output['countries'] = get_country_code(country)\n",
    "        return output\n",
    "    \n",
    "    # if regions_list != None but cities_list == None i need to check if all the regions are in the same country\n",
    "    if (regions_list != None) and (cities_list == None):\n",
    "        if regions_in_same_country(country, regions_list):\n",
    "            output['regions'] = get_regions_id(regions_list)\n",
    "            return output\n",
    "        #else:\n",
    "    \n",
    "    # if regions_list is None but cities_list is not, i have to chech if all the cities are in the same country\n",
    "    if (regions_list == None) and (cities_list != None):\n",
    "        \n",
    "        # if all the cities are in the same country the output is a dictionary with cities as the only key\n",
    "        if cities_in_same_country(country, cities_list):\n",
    "            output['cities'] = get_cities_id(cities_list)\n",
    "            return output\n",
    "        #else:\n",
    "        \n",
    "    # if both regions_list and cities_list are different than None \n",
    "    if (regions_list != None) and (cities_list != None):\n",
    "        \n",
    "        # check if all the cities are in one one of the regions\n",
    "        if cities_in_same_regions(regions_list, cities_list):\n",
    "            output['cities'] = get_cities_id(cities_list)\n",
    "            return output\n",
    "            \n",
    "        # if there are regions containing no cities from cities_list\n",
    "        if len(extra_regions(regions_list, cities_list)) > 0:\n",
    "            output['regions'] = get_regions_id(extra_regions(regions_list, cities_list)) \n",
    "            output['cities'] = get_cities_id(cities_list)\n",
    "            return output\n",
    "        \n",
    "        # if there are cities not contained in regions_list but all the other cities are in the regions_list\n",
    "        if len(extra_cities(regions_list, cities_list)) > 0:\n",
    "            output['regions'] = get_regions_id(extra_regions(regions_list, cities_list)) \n",
    "            output['cities'] = get_cities_id(extra_cities(regions_list, cities_list))\n",
    "            return output\n",
    "        \n",
    "def excluded_geo_locations(country_exclude:str, regions_list_exclude:list, cities_list_exclude:list):\n",
    "    \n",
    "    if  (country_exclude == None) and (regions_list_exclude== None) and (cities_list_exclude==None):\n",
    "        return None\n",
    "    \n",
    "    output = combine_geo_locations(country_exclude, regions_list_exclude, cities_list_exclude)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def get_interest_id_valid(interest:str):\n",
    "    \"\"\"\n",
    "    returns a dictionary containing the interest id and name of an interest  \n",
    "    Important: it returns the result only for the first interest\n",
    "    \"\"\"\n",
    "    \n",
    "    params = {\n",
    "    'type': 'adinterestvalid',\n",
    "    'interest_list': [interest],\n",
    "    }\n",
    "    \n",
    "    # get the answer\n",
    "    resp = TargetingSearch.search(params=params)\n",
    "    #print('resp is {}'.format(resp))\n",
    "    \n",
    "    # select the firts interest\n",
    "    d = resp[0]\n",
    "    if d['valid'] == False:\n",
    "        print('Invalid interest')\n",
    "        return\n",
    "        \n",
    "    #print('d is {}'.format(d))\n",
    "    \n",
    "    keys = [\"id\", \"name\"]\n",
    "    result = { k: d[k] for k in keys}\n",
    "    #result = {'id': d['id']}\n",
    "    #print('result is {}'.format(result))\n",
    "    #print(result)\n",
    "    \n",
    "    return {\"interests\":[result]}\n",
    "\n",
    "def intersecate_interests(interests_list_intersecate):\n",
    "    \"\"\"\n",
    "    intersecates the interests\n",
    "    \"\"\"\n",
    "    \n",
    "    # create a list where to store the final result\n",
    "    inter_ids_list = []\n",
    "    \n",
    "    # iterate over the inderest ang get the relative ids\n",
    "    if inter_ids_list != None:\n",
    "        for i in interests_list_intersecate:\n",
    "            inter_ids_list.append(get_interest_id_valid(str(i)))\n",
    "            \n",
    "    return inter_ids_list\n",
    "\n",
    "def combine_interests(interests_list_combine:list):\n",
    "    \"\"\"\n",
    "    combines the interets \n",
    "    \"\"\"\n",
    "    \n",
    "    # the result needs to be a list of dictionaries\n",
    "    # create a list where to store the final result\n",
    "    output = []\n",
    "    \n",
    "    if interests_list_combine == None:\n",
    "        return None\n",
    "    \n",
    "    for i in interests_list_combine:\n",
    "        # get the dictionary containing the id and the name of the interest and append it to the output\n",
    "        output.append(get_interest_id_valid(str(i))['interests'][0])\n",
    "        \n",
    "    return output\n",
    "\n",
    "def add_interests(interests_list:list, interests_list_or:list):\n",
    "    \n",
    "    \"\"\"\n",
    "    returns a list containing both the combined and intersecated interests\n",
    "    \"\"\"\n",
    "    if (interests_list == None) and (interests_list_or == None):\n",
    "        return None\n",
    "    \n",
    "    elif (interests_list != None) and (interests_list_or == None):\n",
    "        \n",
    "        # first get the intersecated outputs\n",
    "        output = intersecate_interests(interests_list)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    elif (interests_list == None) and (interests_list_or != None):\n",
    "        \n",
    "        d = {}\n",
    "        d['interests'] = combine_interests(interests_list_or)\n",
    "        return [d]\n",
    "    \n",
    "    elif (interests_list != None) and (interests_list_or != None):\n",
    "    \n",
    "        # first get the intersecated outputs\n",
    "        output = intersecate_interests(interests_list) \n",
    "\n",
    "        # add the or-interests\n",
    "        d = {}\n",
    "        d['interests'] = combine_interests(interests_list_or)\n",
    "        output.append(d)\n",
    "\n",
    "        return output\n",
    "\n",
    "# create a dictionary for all possible classes\n",
    "ad_targeting_category_dict = {}\n",
    "\n",
    "classes_list = 'behaviors demographics life_events industries income family_statuses user_device user_os'.split()\n",
    "\n",
    "# iterate over the possible classes\n",
    "for cl in classes_list:\n",
    "    \n",
    "    params = {\n",
    "    'type' : 'adTargetingCategory',\n",
    "    'class': cl\n",
    "    }\n",
    "    \n",
    "    resp = TargetingSearch.search(params=params)\n",
    "    \n",
    "    ad_targeting_category_dict[cl] = {r['name']:r for r in resp}\n",
    "    \n",
    "def get_all_behaviors():\n",
    "    \"\"\"\n",
    "    returns a list containing all the possible behaviors\n",
    "    \"\"\"\n",
    "    \n",
    "    return list(ad_targeting_category_dict['behaviors'].keys())\n",
    "\n",
    "def get_behaviors_id(behaviors_list:list):\n",
    "    \n",
    "    if behaviors_list == None:\n",
    "        return None\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for b in behaviors_list:\n",
    "        b_id = ad_targeting_category_dict['behaviors'][b]['id']\n",
    "        res.append({'id':b_id})\n",
    "        \n",
    "    return res\n",
    "\n",
    "def get_all_life_events():\n",
    "    \"\"\"\n",
    "    returns a list containing all the possible life_events\n",
    "    \"\"\"\n",
    "    \n",
    "    return list(ad_targeting_category_dict['life_events'].keys())\n",
    "\n",
    "def get_life_events_id(life_events_list:list):\n",
    "    \n",
    "    \"\"\"\n",
    "    IMPORTANT: if you pass more than one life_event the result will be the sum and not the intersection\n",
    "    of those life events. This makes sense since many are mutually exlusive (such as Fidanzati da 6 mesi e \n",
    "    fidanzati da 1 anno)\n",
    "    \"\"\"\n",
    "    if life_events_list == None:\n",
    "        return None\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for b in life_events_list:\n",
    "        b_id = ad_targeting_category_dict['life_events'][b]['id']\n",
    "        res.append({'id':b_id})\n",
    "        \n",
    "    return res\n",
    "\n",
    "def get_all_industries():\n",
    "    \"\"\"\n",
    "    returns a list containing all the possible industries\n",
    "    \"\"\"\n",
    "    \n",
    "    return list(ad_targeting_category_dict['industries'].keys())\n",
    "\n",
    "def get_industries_id(industries_list:list):\n",
    "    \n",
    "    if industries_list == None:\n",
    "        return None\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for b in industries_list:\n",
    "        b_id = ad_targeting_category_dict['industries'][b]['id']\n",
    "        res.append({'id':b_id})\n",
    "        \n",
    "    return res\n",
    "\n",
    "def get_all_family_statuses():\n",
    "    \"\"\"\n",
    "    returns a list containing all the possible family_statuses\n",
    "    \"\"\"\n",
    "    \n",
    "    return list(ad_targeting_category_dict['family_statuses'].keys())\n",
    "\n",
    "def get_family_statuses_id(family_statuses_list:list):\n",
    "    \n",
    "    if family_statuses_list == None:\n",
    "        return None\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for b in family_statuses_list:\n",
    "        b_id = ad_targeting_category_dict['family_statuses'][b]['id']\n",
    "        res.append({'id':b_id})\n",
    "        \n",
    "    return res\n",
    "\n",
    "def get_all_relationship_statuses():\n",
    "    \"\"\"\n",
    "    returns a dictionary containing the relationship statuses and the corresponding ids\n",
    "    \"\"\"\n",
    "    \n",
    "    # save all possible relationship statuses in a list\n",
    "    rel_statuses = \"\"\" single in_relationship married engaged empty_space not_specified civil_union domestic_partnership \n",
    "                    open_relationship It's_complicated Separated Divorced Widowed\"\"\".split()\n",
    "    \n",
    "    # create a dictionary containing the relationship status and the corresponding id\n",
    "    d = {rel_statuses[i]: i+1 for i in range(len(rel_statuses))}\n",
    "    \n",
    "    del d['empty_space']\n",
    "    \n",
    "    return d\n",
    "\n",
    "def get_relationship_statuses_id(relationship_statuses_list:list):\n",
    "    \n",
    "    if relationship_statuses_list == None:\n",
    "        return None\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for rs in relationship_statuses_list:\n",
    "        rs_id = get_all_relationship_statuses()[rs]\n",
    "        res.append(rs_id)\n",
    "        \n",
    "    return res\n",
    "\n",
    "def create_custom_location(min_population:int, max_population:int, country:str, custom_type = 'multi_city'):\n",
    "    \n",
    "    \"\"\"\n",
    "    IMPORTANT min_population needs to be at least 100000\n",
    "    \"\"\"\n",
    "    # create a dictionary where to store the result\n",
    "    res = {}\n",
    "    \n",
    "    # create an inner dictionary where to store the parameters\n",
    "    params = {}\n",
    "    params['custom_type'] = custom_type\n",
    "    params['min_population'] = min_population\n",
    "    params['max_population'] = max_population\n",
    "    params['country'] = get_country_code(country)[0]\n",
    "    \n",
    "    res['custom_locations'] = [params]\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_education_schools_id(school_name:str):\n",
    "    \"\"\"\n",
    "    returns the id and the name of a university\n",
    "    WARNING: in case of multiple universities with the same name it returns the first result\n",
    "    \"\"\"\n",
    "    \n",
    "    if school_name == None:\n",
    "        return None\n",
    "    \n",
    "    params = {\n",
    "        'q': school_name,\n",
    "        'type': 'adeducationschool',\n",
    "    }\n",
    "    resp = TargetingSearch.search(params=params)\n",
    "    \n",
    "    # select the first result\n",
    "    d = resp[0]\n",
    "    \n",
    "    # keep only the id and the name \n",
    "    keys = [\"id\", \"name\"]\n",
    "    result = { k: d[k] for k in keys}\n",
    "    return result\n",
    "\n",
    "def combine_education_schools(schools_list:list):\n",
    "    \"\"\"\n",
    "    combines multiple results from get_education_schools_id into a list\n",
    "    \"\"\"\n",
    "    if schools_list == None:\n",
    "        return None\n",
    "    \n",
    "    # create a list\n",
    "    output = []\n",
    "    \n",
    "    for s in schools_list:\n",
    "        output.append(get_education_schools_id(s))\n",
    "        \n",
    "    return output\n",
    "\n",
    "def get_all_education_statuses():\n",
    "    \"\"\"\n",
    "    returns a dictionary containing all the education statuses and the corresponding ids\n",
    "    \"\"\"\n",
    "    \n",
    "    # save all the possible statuses in a list\n",
    "    edu_statuses = \"\"\"HIGH_SCHOOL UNDERGRAD ALUM HIGH_SCHOOL_GRAD SOME_COLLEGE ASSOCIATE_DEGREE IN_GRAD_SCHOOL \n",
    "    SOME_GRAD_SCHOOL MASTER_DEGREE PROFESSIONAL_DEGREE DOCTORATE_DEGREE UNSPECIFIED SOME_HIGH_SCHOOL\"\"\".lower().split()\n",
    "    \n",
    "    # create a dictionary containing the relationship status and the corresponding id\n",
    "    d = {edu_statuses[i]: i+1 for i in range(len(edu_statuses))}\n",
    "    \n",
    "    return d\n",
    "\n",
    "def get_education_statuses_id(education_statuses_list:list):\n",
    "    \"\"\"\n",
    "    returns a list containing the id of the education_statuses selected\n",
    "    \"\"\"\n",
    "    \n",
    "    if education_statuses_list == None:\n",
    "        return None\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    for es in education_statuses_list:\n",
    "        es_id = get_all_education_statuses()[es]\n",
    "        output.append(es_id)\n",
    "        \n",
    "    return output\n",
    "\n",
    "def get_education_majors_id(major:str):\n",
    "    \"\"\"\n",
    "    returns the id and the name of a major\n",
    "    WARNING: in case of multiple majors with the same name it returns the first result\n",
    "    \"\"\"\n",
    "    \n",
    "    params = {\n",
    "        'q': major,\n",
    "        'type': 'adeducationmajor',\n",
    "    }\n",
    "\n",
    "    resp = TargetingSearch.search(params=params)\n",
    "    \n",
    "    # select the first result\n",
    "    d = resp[0]\n",
    "    \n",
    "    # keep only the id and the name \n",
    "    keys = [\"id\", \"name\"]\n",
    "    result = { k: d[k] for k in keys}\n",
    "    return result\n",
    "\n",
    "def combine_education_majors(majors_list:list):\n",
    "    \"\"\"\n",
    "    combines multiple results from get_education_majors_id into a list\n",
    "    \"\"\"\n",
    "    if majors_list == None:\n",
    "        return None\n",
    "    \n",
    "    # create empty list\n",
    "    output = []\n",
    "    \n",
    "    for m in majors_list:\n",
    "        output.append(get_education_majors_id(m))\n",
    "    \n",
    "    return output\n",
    "\n",
    "def get_work_employers(employer:str, return_all = False):\n",
    "    \"\"\"\n",
    "    returns the id and the name of an employer\n",
    "    WARNING: in case of multiple employers with the same name it returns the first result\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'q': employer,\n",
    "        'type': 'adworkemployer',\n",
    "    }\n",
    "\n",
    "    resp = TargetingSearch.search(params=params)\n",
    "    \n",
    "    if return_all == True:\n",
    "        return resp\n",
    "    \n",
    "    else:\n",
    "        # select the first result\n",
    "        d = resp[0]\n",
    "\n",
    "        # keep only the id and the name \n",
    "        keys = [\"id\", \"name\"]\n",
    "        result = { k: d[k] for k in keys}\n",
    "        return result\n",
    "    \n",
    "def combine_work_employers(employers_list:list):\n",
    "    \"\"\"\n",
    "    combines multiple results from get_work_employers into a list\n",
    "    \"\"\"\n",
    "    \n",
    "    if employers_list == None:\n",
    "        return None\n",
    "    \n",
    "    # create empty list\n",
    "    output = []\n",
    "    \n",
    "    for e in employers_list:\n",
    "        output.append(get_work_employers(e))\n",
    "    \n",
    "    return output\n",
    "\n",
    "def get_work_positions(work_position:str, return_all = False):\n",
    "    \"\"\"\n",
    "    returns the id and the name of a work_position\n",
    "    WARNING: in case of multiple employers with the same name it returns the first result\n",
    "    if return_all is set to false\n",
    "    \"\"\"\n",
    "    \n",
    "    params = {\n",
    "        'q': work_position,\n",
    "        'type': 'adworkposition',\n",
    "    }\n",
    "\n",
    "    resp = TargetingSearch.search(params=params)\n",
    "    \n",
    "    if len(resp) == 0:\n",
    "        print('Work position not found, try again')\n",
    "        return\n",
    "    \n",
    "    if return_all == True:\n",
    "        return resp\n",
    "    \n",
    "    else:\n",
    "        # select the first result\n",
    "        d = resp[0]\n",
    "\n",
    "        # keep only the id and the name \n",
    "        keys = [\"id\", \"name\"]\n",
    "        result = { k: d[k] for k in keys}\n",
    "        return result\n",
    "    \n",
    "def combine_work_positions(work_positions_list:list):\n",
    "    \"\"\"\n",
    "    combines multiple results from get_work_positions into a list\n",
    "    \"\"\"\n",
    "    \n",
    "    if work_positions_list == None:\n",
    "        return None\n",
    "    \n",
    "    # create empty list\n",
    "    output = []\n",
    "    \n",
    "    for wp in work_positions_list:\n",
    "        output.append(get_work_positions(wp))\n",
    "    \n",
    "    return output\n",
    "\n",
    "def intersecate_behaviors(behaviors_list_intersecate:list):\n",
    "    \"\"\"\n",
    "    intersecate behaviors and returns a list of dictionaries, all with the same key in \n",
    "    \"\"\"\n",
    "    \n",
    "    if behaviors_list_intersecate == None:\n",
    "        return None\n",
    "    \n",
    "    # create a list where to store the final result\n",
    "    output = []\n",
    "    \n",
    "    # iterate over all the behaviors and get the relative id and create a dictionary with key 'behaviors'\n",
    "    for b in behaviors_list_intersecate:\n",
    "        temp_d = {}\n",
    "        temp_d['behaviors'] = get_behaviors_id([b])\n",
    "        output.append(temp_d)\n",
    "        \n",
    "    return output\n",
    "\n",
    "def combine_behaviors(behaviors_list_combine:list):\n",
    "    \"\"\"\n",
    "    returns a list of dictionaries containing all the behaviors id combined\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    d = {}\n",
    "    d['behaviors'] = get_behaviors_id(behaviors_list_combine)\n",
    "    output.append(d)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def add_behaviors(behaviors_list_intersecate, behaviors_list_combine):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    if (behaviors_list_intersecate == None) and (behaviors_list_combine) == None:\n",
    "        return None\n",
    "    \n",
    "    elif (behaviors_list_intersecate!= None) and (behaviors_list_combine) == None:\n",
    "        #get only the intersecated behaviors\n",
    "        output = intersecate_behaviors(behaviors_list_intersecate)\n",
    "        return output\n",
    "    \n",
    "    elif (behaviors_list_intersecate== None) and (behaviors_list_combine) != None:\n",
    "        \n",
    "        return combine_behaviors(behaviors_list_combine)\n",
    "    \n",
    "    else:\n",
    "        # first get the intersecated behaviors\n",
    "        output = intersecate_behaviors(behaviors_list_intersecate)\n",
    "        \n",
    "        # the add the combined behaviors\n",
    "        for i in combine_behaviors(behaviors_list_combine):\n",
    "            output.append(i)\n",
    "            \n",
    "        return output\n",
    "    \n",
    "def create_flexible_spec(interests_list_intersecate, \n",
    "                         interests_list_combine, \n",
    "                         behaviors_list_intersecate, \n",
    "                         behaviors_list_combine):\n",
    "    \"\"\"\n",
    "    combines the results from add_behaviors and add_interests and returns a list\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    \n",
    "    if (add_interests(interests_list_intersecate, interests_list_combine) == None) and (add_behaviors(behaviors_list_intersecate, behaviors_list_combine) == None):\n",
    "        return None\n",
    "    \n",
    "    if (add_interests(interests_list_intersecate, interests_list_combine) == None):\n",
    "        for b in add_behaviors(behaviors_list_intersecate, behaviors_list_combine):\n",
    "            output.append(b)\n",
    "        return output\n",
    "    \n",
    "    if add_behaviors(behaviors_list_intersecate, behaviors_list_combine) == None:\n",
    "        for i in add_interests(interests_list_intersecate, interests_list_combine):\n",
    "            output.append(i)\n",
    "        return output\n",
    "    \n",
    "    #if add_interests(interests_list_intersecate, interests_list_combine) != None: \n",
    "    for i in add_interests(interests_list_intersecate, interests_list_combine):\n",
    "        output.append(i)\n",
    "        \n",
    "    #elif add_behaviors(behaviors_list_intersecate, behaviors_list_combine) != None:\n",
    "    for b in add_behaviors(behaviors_list_intersecate, behaviors_list_combine):\n",
    "        output.append(b)\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_market_size(Ad_Account_num, \n",
    "                    country: str, \n",
    "                    regions_list:None, \n",
    "                    cities_list:list, \n",
    "                    interests_list_intersecate:list, \n",
    "                    interests_list_combine:list,\n",
    "                    age_min:int, \n",
    "                    age_max:int,\n",
    "                    behaviors_list_intersecate:list,\n",
    "                    behaviors_list_combine:list,\n",
    "                    life_events_list:list,\n",
    "                    industries_list:list,\n",
    "                    family_statuses_list:list,\n",
    "                    relationship_statuses_list:list,\n",
    "                    schools_list:list,\n",
    "                    education_statuses_list:list,\n",
    "                    majors_list:list,\n",
    "                    employers_list:list,\n",
    "                    work_positions_list: list,\n",
    "                    min_population:int, \n",
    "                    max_population:int,\n",
    "                    custom_location = False,\n",
    "                    gender_list = [1,2],\n",
    "                    country_exclude = None,\n",
    "                    regions_list_exclude = None,\n",
    "                    cities_list_exclude = None\n",
    "                   ):\n",
    "    \n",
    "    \"\"\"\n",
    "    returns the potential market size given the characteristics selected\n",
    "    \n",
    "    If you want to custom location you need to set custom_location to True\n",
    "    \"\"\"\n",
    "                \n",
    "    \n",
    "    params = {\n",
    "        'targeting_spec': {\n",
    "            \n",
    "            'geo_locations': combine_geo_locations(country, regions_list, cities_list),\n",
    "            \n",
    "            'excluded_geo_locations': excluded_geo_locations(country_exclude, regions_list_exclude, cities_list_exclude),\n",
    "            \n",
    "            'age_min':age_min,\n",
    "            'age_max':age_max,\n",
    "\n",
    "            #'flexible_spec': add_interests(interests_list, interests_list_or),\n",
    "            'flexible_spec':create_flexible_spec(interests_list_intersecate, \n",
    "                                                    interests_list_combine, \n",
    "                                                    behaviors_list_intersecate, \n",
    "                                                    behaviors_list_combine),\n",
    "            \n",
    "            #'behaviors': get_behaviors_id(behaviors_list), \n",
    "            \n",
    "            'life_events': get_life_events_id(life_events_list),\n",
    "            \n",
    "            'industries': get_industries_id(industries_list),\n",
    "            \n",
    "            'family_statuses': get_family_statuses_id(family_statuses_list),\n",
    "            \n",
    "            'relationship_statuses': get_relationship_statuses_id(relationship_statuses_list),\n",
    "            \n",
    "            'genders': gender_list,\n",
    "            \n",
    "            'education_schools': combine_education_schools(schools_list),\n",
    "            \n",
    "            'education_statuses': get_education_statuses_id(education_statuses_list),\n",
    "            \n",
    "            'education_majors': combine_education_majors(majors_list),\n",
    "            \n",
    "            'work_employers': combine_work_employers(employers_list),\n",
    "            \n",
    "            'work_positions': combine_work_positions(work_positions_list),\n",
    "        }}\n",
    "    \n",
    "    #update geo_locations if custom_location is true\n",
    "    if custom_location == True:\n",
    "        params['targeting_spec']['geo_locations'] = create_custom_location(min_population, max_population, country)\n",
    "        \n",
    "    \n",
    "    res = AdAccount(Ad_Account_num).get_reach_estimate(params=params)[0]\n",
    "    \n",
    "    estimate = res['users']\n",
    "    \n",
    "    print('The estimate for this target market is {}'.format(estimate))\n",
    "    \n",
    "    return estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all the relevant parameters\n",
    "interests_list_intersecate = ['Caffè','Cocktail','Viaggi in aereo']\n",
    "behaviors_list_intersecate = ['Viaggiatori frequenti', 'Viaggiatori internazionali abituali']\n",
    "gender_list = [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimate for this target market is 370000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "370000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_market_size(Ad_Account_num,\n",
    "                country = 'Italy',\n",
    "                regions_list = None,\n",
    "                cities_list = None,           \n",
    "                interests_list_intersecate = interests_list_intersecate, \n",
    "                interests_list_combine = None,\n",
    "                age_min = 18,\n",
    "                age_max = 35,\n",
    "                behaviors_list_intersecate = behaviors_list_intersecate,\n",
    "                behaviors_list_combine = None,\n",
    "                life_events_list = None, \n",
    "                industries_list = None, \n",
    "                family_statuses_list = None, \n",
    "                relationship_statuses_list = None, \n",
    "                schools_list = None,\n",
    "                education_statuses_list = None,\n",
    "                majors_list = None,\n",
    "                employers_list = None,\n",
    "                work_positions_list = None,\n",
    "                custom_location=False,\n",
    "                min_population = 120000,\n",
    "                max_population = 550000,\n",
    "                gender_list=gender_list,\n",
    "                country_exclude= None,\n",
    "                regions_list_exclude=None,\n",
    "                cities_list_exclude=None,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "interests_list_intersecate = ['Caffè','Cocktail','Viaggi in aereo', 'Glamour (rivista)', 'Dolce','Handmade']\n",
    "behaviors_list_intersecate = ['Viaggiatori frequenti',\n",
    "                  'Viaggiatori internazionali abituali',\n",
    "                   'Accesso a Facebook (mobile): smartphone e tablet' ]\n",
    "\n",
    "# Here we combine to obtain the info on who has been using a mobile device\n",
    "# for more than 19 months\n",
    "behaviors_list_combine = ['Usa un dispositivo mobile (più di 25 mesi)','Usa un dispositivo mobile (19-24 mesi)']\n",
    "# only females\n",
    "gender_list = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimate for this target market is 7100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7100"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_market_size(Ad_Account_num,\n",
    "                country = 'Italy',\n",
    "                regions_list = None,\n",
    "                cities_list = None,           \n",
    "                interests_list_intersecate = interests_list_intersecate, \n",
    "                interests_list_combine = None,\n",
    "                age_min = 20,\n",
    "                age_max = 30,\n",
    "                behaviors_list_intersecate = behaviors_list_intersecate,\n",
    "                behaviors_list_combine = behaviors_list_combine,\n",
    "                life_events_list = None, \n",
    "                industries_list = None, \n",
    "                family_statuses_list = None, \n",
    "                relationship_statuses_list = None, \n",
    "                schools_list = None,\n",
    "                education_statuses_list = None,\n",
    "                majors_list = None,\n",
    "                employers_list = None,\n",
    "                work_positions_list = None,\n",
    "                custom_location=False,\n",
    "                min_population = 120000,\n",
    "                max_population = 550000,\n",
    "                gender_list=gender_list,\n",
    "                country_exclude= None,\n",
    "                regions_list_exclude=None,\n",
    "                cities_list_exclude=None,\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='Andrea'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = #D09E00 > \tAndrea, the business man\n",
    "\n",
    "[Back on top](#top)\n",
    "## <font color = #D09E00 > 1.4\tAndrea’s description\n",
    "Andrea lives in a big city and shares a fancy flat with his girlfriend. He is a competitive hard worker, always putting in his best effort in everything he does. He is very busy, due to his overachieving nature, but he finds time to attend events and to be with his girlfriend or his friends, who he always tries to impress.\n",
    "He is a sophisticated person, always seeking the pleasure of the senses; he likes photography and arts in general  and is interested in wine and good food.\n",
    "\n",
    "We used the social media analysis work reported in (Final_WAS_Y&R_Lavazza_ContentStrategy_2019_040519.pdf, slide 44) to be sure that the mentioned interests are relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = #D09E00 > 1.5\tAndrea’s customer journey as-is\n",
    "Coffee is a part of his lifestyle and a reward for his sophisticated personality.\n",
    "For him, coffee moments represent:\n",
    "-\tsocial opportunities to share with his friends or girlfriend, possibly in a cool place like the flagship store \n",
    "-\tpremium experiences in which to taste the amazing flavor of coffee. \n",
    "\n",
    "Therefore, he is both a pleasure and status seeker.\n",
    "He tends to consume 2 coffees per day:\n",
    "\n",
    "The **first coffee** is in the morning. Andrea wants to start the day with coffee taste in his mouth, and not just the coffee but the preparation as well is part of his morning ritual. \n",
    "He is aware that only if made by him, or by a qualified barista, a coffee can satisfy his taste, as he knows the right combination of ingredients and timings, on top of the procedure to give the coffee the particular features he is seeking.\n",
    "For these reasons he gladly prepares the coffee by himself, enjoying choosing the perfect blend (among the wide variety of Lavazza blends he preserves in airtight containers) and doing all the steps his perfect coffee requires. \n",
    "In the morning coffee represents a moment of pleasure to be enjoyed, alone or with his girlfriend, in the peaceful atmosphere of his home. Neither the coffee from the automatic distributors at the workplace nor that taken in the nearest bar can be good substitutes. \n",
    "\n",
    "**Emotional driver**: pleasure seeking \n",
    "\n",
    "The **second coffee** is taken:\n",
    "\n",
    "-\tduring the weekend afternoons, while spending pleasant social time surrounded by his friends or colleagues in a fancy place, possibly trying to impress them by choosing among different brands and varieties, thus showing his coffee expertise, but without missing out on the opportunity to upload some Instagram stories.\n",
    "Functional drivers: status seeking. He has to show the coffee as a symbol, signaling his tastes and aesthetics.\n",
    "Emotional drivers: need for interpersonal interactions \n",
    "-\tduring the week, in the post-dinner evenings spent at home. Here coffee represents a moment to be shared with his girlfriend, allowing him to the end the day on a positive note, while possibly using coffee also as a digestive in this occasion.\n",
    "\n",
    "    **Functional drivers**: need for a digestive, \n",
    "    alternative for the coffee he could not have taken in the afternoon \n",
    "\n",
    "    **Emotional drivers**: ending the day in a pleasant way, having a sort of  ‘reward’ after a  busy day\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Main pain point in his general costumer journey**\n",
    "\n",
    "\n",
    "The principal problem for Andrea is not having the opportunity to live to the fullest the afternoon coffee sharing/social moments. Indeed, during working afternoons, he can’t enjoy a premium and quality coffee experience with his friends of colleagues, as his best bet would be to call the serving from the nearest bar, or use the vendor machines during a break.\n",
    "\n",
    "\n",
    "Therefore, while he is able to satisfy his ‘pleasure need’ by preparing good coffee at home both in the mornings and in the evenings, on the other hand, during the week, he needs some social moments during which high-quality coffee acts as a sort of symbol of his lifestyle, an opportunity to show his social status. Furthermore, we imagined some moments in which Andrea may have a coffee, but, looking at internal data (U&A italia 2016, slide 18), we can fairly rightly think that a certan number of Andreas isn't even able to get coffee during the week: workplace is, for many people, their only chance to have a coffee during the day, and it makes up for 30% of the outside-home consumption\n",
    "\n",
    "\n",
    "This pain point in his customer journey is easily solved by the product we are proposing.\n",
    "Indeed, our kit would allow him to live a reinvented coffee experience at a time of the afternoon usually dedicated to aperitives more than to coffees, so he could invite his friends or colleagues at home after work, offering them sophisticated coffee-based drinks.\n",
    "In this way he would be able to impress them while spending some good time in company enjoying coffee at an otherwise unusual time.\n",
    "\n",
    "\n",
    "Our product would also be a good alternative to the after-dinner coffee, since it offers him a way to end the days a bit differently, without having to give up on the coffee taste. \n",
    "In general, our product would be appealing to him for several reasons: first of all it brings together two otherwise different worlds, the aperitif and the coffee one, which he likes both. On top of this, it allows himself to live high status experiences with his friends, during which he can fully express his capabilities. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = #D09E00 > 1.6\tAndrea’s Market size\n",
    "\n",
    "In accordance with the persona developed so far, we believe that our target is composed of those individuals who are interested not only in coffee and aperitifs but also in other activities such as photography and cooking. Moreover, they are engaged, between 26 and 35 years old, live in Italy and work in a field such as management, finance, sales, architecture/engineering or legal services. Using our function, we found out that there are about 2.700 people corresponding to all these criteria.\n",
    "\n",
    "We have obtained a very low number. However, not everyone on Facebook tends to specify the kind of industry their job belongs to. Consequently, we have decided to re-estimate our market size, but this time without setting any restriction in terms of industries. Given this new criterion, we obtain an estimate of 68.000  individuals, a result showing a promising potential for this new product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters for Andrea\n",
    "interests_list_intersecate = ['Caffè','Aperitivo']\n",
    "#industries_list = ['Aziende e finanza', 'Management', 'Vendite']\n",
    "relationship_statuses_list = ['in_relationship', 'married','engaged','open_relationship']\n",
    "gender_list = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimate for this target market is 140000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "140000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_market_size(Ad_Account_num,\n",
    "                country = 'Italy',\n",
    "                regions_list = None,\n",
    "                cities_list = None,           \n",
    "                interests_list_intersecate = interests_list_intersecate, \n",
    "                interests_list_combine = None,\n",
    "                age_min = 26,\n",
    "                age_max = 35,\n",
    "                behaviors_list_intersecate = None, \n",
    "                behaviors_list_combine=None,\n",
    "                life_events_list = None, \n",
    "                industries_list = None, #industries_list, \n",
    "                family_statuses_list = None, \n",
    "                relationship_statuses_list = relationship_statuses_list, \n",
    "                schools_list = None,\n",
    "                education_statuses_list = None,\n",
    "                majors_list = None,\n",
    "                employers_list = None,\n",
    "                work_positions_list = None,\n",
    "                custom_location=False,\n",
    "                min_population = 120000,\n",
    "                max_population = 550000,\n",
    "                gender_list=gender_list,\n",
    "                country_exclude= None,\n",
    "                regions_list_exclude=None,\n",
    "                cities_list_exclude=None,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters for Andrea\n",
    "interests_list_intersecate = ['Caffè','Aperitivo','Cucina','Fotografia']\n",
    "industries_list = ['Aziende e finanza', 'Management', 'Vendite']\n",
    "relationship_statuses_list = ['in_relationship', 'married','engaged','open_relationship']\n",
    "gender_list = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimate for this target market is 1700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1700"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_market_size(Ad_Account_num,\n",
    "                country = 'Italy',\n",
    "                regions_list = None,\n",
    "                cities_list = None,           \n",
    "                interests_list_intersecate = interests_list_intersecate, \n",
    "                interests_list_combine = None,\n",
    "                age_min = 26,\n",
    "                age_max = 35,\n",
    "                behaviors_list_intersecate = None,\n",
    "                behaviors_list_combine=None,\n",
    "                life_events_list = None, \n",
    "                industries_list = industries_list, \n",
    "                family_statuses_list = None, \n",
    "                relationship_statuses_list = relationship_statuses_list, \n",
    "                schools_list = None,\n",
    "                education_statuses_list = None,\n",
    "                majors_list = None,\n",
    "                employers_list = None,\n",
    "                work_positions_list = None,\n",
    "                custom_location=False,\n",
    "                min_population = 120000,\n",
    "                max_population = 550000,\n",
    "                gender_list=gender_list,\n",
    "                country_exclude= None,\n",
    "                regions_list_exclude=None,\n",
    "                cities_list_exclude=None,\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='Marta'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = #C45911> \tMarta, the off-site student\n",
    "    \n",
    "[Back on top](#top)\n",
    "## <font color = #C45911 > 1.7\tMarta’s description\n",
    "Age: 18/25 years old. \n",
    "\n",
    "Personal description: \n",
    "-\tMarta is an off-site university student, living in a new city.\n",
    "-\tShe is committed to her studies and used to study ‘till late. \n",
    "-\tShe is socially active, always looking for social interactions, engaged on social networks, trend follower.\n",
    "-\tHer budget is not so high, she can’t frequently afford expensive night-outs, so she is used to home partying.\n",
    "-\tStatus seeker: she is interested in other people’s opinion; she is looking for approval. \n",
    "-\tInterested in art, culture, and music, especially Italian [pop-indie](https://www.facebook.com/ads/audience-insights/interests?act=235630865&age=18-25&country=IT&education=3&gender=1&interests=6003210597333) one ; she is a concert goer.\n",
    "\n",
    "Marta as a coffee consumer:\n",
    "-\tShe has started recently to drink coffee\n",
    "-\tShe is too young to appreciate the more adult “coffee mood”-\tUsed to take coffee at university bar, or at the automatic distributor \n",
    "-\tCoffee consumer more for necessity (study needs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = #C45911 > 1.8 Marta’s customer journey as-is\n",
    "*Marta’s coffee journey depends on her routine and on her daily timetable. She always drinks it in the morning and after lunch, while the one during the day is more aleatory. Marta has a strict routine; coffee is a complementary aspect of it. Also due to the fact that she is not a “veteran” of coffee consumption, she hasn’t developed yet a strong affection or belonging to a particular brand, her main driver is purely functional.*\n",
    "    \n",
    "    \n",
    "#### *From Monday to Friday:*\n",
    "\n",
    "\n",
    "The first coffee is in the morning; due to time constraints and since she cannot really afford a coffee machine, she often doesn’t have it at home. \n",
    "Therefore, she opts for two different paths: \n",
    "-\t**Bar** -> Aside from other constraints, when she has time, this is her best call. Indeed she enjoys having a rounded experience, a satisfying moment for interpersonal interactions, the possibility of uploading IG stories, gaining higher status perception. She takes coffee without caring too much about brand or quality, the important thing is being with others. Her first choice is a macchiato or a cappuccino, not a basic espresso. Sometimes she has a complete breakfast also consuming food. In that case she enjoys the moment at the fullest.\n",
    "\n",
    "-\t**Vendor machine** -> faster, cheaper, satisfies the need for a pre-lecture boost of energy, but does not satisfy anything in the emotional sphere. In this case she likely had breakfast at home. \n",
    "\n",
    "Drivers:\n",
    "-\t**functional**: energy boost \n",
    "-\t**emotional**: need for aggregation, improvement of her social image \n",
    "\n",
    "**The second coffee**:  the second coffee is taken after lunch. This coffee is totally functional driven, she needs to be mentally performing also after lunch, due to coming lessons or to her studying duties. \n",
    "Whether it is in a bar adjacent to the university, at home, or at the machines, coffee is taken according to the afternoon work. More than a ritual the attitude toward consumption is still a necessity.\n",
    "\n",
    "\n",
    "Drivers:\n",
    "-\t**functional**: coffee is a recovery from lunch, a digestive \n",
    "-\t**emotional**: it is a brief moment of peace before another session of work\n",
    "\n",
    "**The bonus coffee**: An occasion for a mid-morning break between to lectures. It is a fast coffee, a chance to share a sparing moment with her class peers. She does not enjoy the coffee moment in general as it is merely functional.\n",
    "\n",
    "\n",
    "#### *The weekend:*\n",
    "\n",
    "Marta exploits weekend’s night to meet people and satisfy her social needs both Friday and Saturday night she meets friends. \n",
    "There are mainly three moments to analyse: aperitif, dinner, and pre-night.\n",
    "\n",
    "As for the aperitif, if she decides to go out, she usually does not consume coffee: she prefers an Aperol spritz or Hugo, or even a beer if not a more sophisticated cocktail. She looks for good price, while she cares for being good looking as well, thus having something cool in her glass as well. She wants to take photos, make IG stories, and let people know she is living a great moment.\n",
    "\n",
    "\n",
    "The alternative would be to chill at home and get a rest before the night out. In this case she would drink a beer with some friends. \n",
    "\n",
    "\n",
    "While aperitif and nights are the moments in which she goes out to have fun, due to budget constraints she sometimes organizes dinners at home with friends: she cannot afford restaurants (if not rarely), that she would otherwise prefer. \n",
    "Which function does coffee have in these moments? She usually prepares an after-dinner coffee with the moka, sharing it with her friends or house-mates, to be active during the pre-night and to start getting in the mood (an alternative to this moment could be home-made drinks with alcohol and energy drinks, but a slightly different costumer journey should be taken in consideration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = #C45911 > 1.9\tMarta’s Market size\n",
    "    \n",
    "Firstly we got a broad idea of off-site female students interested in aperitifs, cocktails or coffee, getting an estimate of 58000. Restricting to an interest both in coffe and aperitifs, we obtain an estimate of 16000\n",
    "\n",
    "\n",
    "[Back on top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all the relevant parameters\n",
    "interests_list_combine = ['Cappuccino', 'Caffè','Cocktail', 'Aperol', 'Aperitivo', 'Campari','Bacardi','drink']\n",
    "education_statuses_list = ['undergrad', 'in_grad_school','master_degree','professional_degree']\n",
    "life_events_list = [\"Lontano dalla città di origine\"]\n",
    "gender_list = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimate for this target market is 58000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_market_size(Ad_Account_num,\n",
    "                country = 'Italy',\n",
    "                regions_list = None,\n",
    "                cities_list = None,           \n",
    "                interests_list_intersecate = None, \n",
    "                interests_list_combine=  interests_list_combine,\n",
    "                age_min = 18,\n",
    "                age_max = 25,\n",
    "                behaviors_list_intersecate = None,\n",
    "                behaviors_list_combine = None,\n",
    "                life_events_list = life_events_list, \n",
    "                industries_list = None, \n",
    "                family_statuses_list = None, \n",
    "                relationship_statuses_list = None, \n",
    "                schools_list = None,\n",
    "                education_statuses_list = education_statuses_list,\n",
    "                majors_list = None,\n",
    "                employers_list = None,\n",
    "                work_positions_list = None,\n",
    "                custom_location=False,\n",
    "                min_population = 120000,\n",
    "                max_population = 550000,\n",
    "                gender_list=gender_list,\n",
    "                country_exclude= None,\n",
    "                regions_list_exclude=None,\n",
    "                cities_list_exclude=None,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "interests_list_intersecate = ['Caffè','Aperitivo',]\n",
    "education_statuses_list = ['undergrad', 'in_grad_school','master_degree']\n",
    "life_events_list = [\"Lontano dalla città di origine\"]\n",
    "gender_list = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimate for this target market is 16000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_market_size(Ad_Account_num,\n",
    "                country = 'Italy',\n",
    "                regions_list = None,\n",
    "                cities_list = None,           \n",
    "                interests_list_intersecate = interests_list_intersecate, \n",
    "                interests_list_combine = None,\n",
    "                age_min = 18,\n",
    "                age_max = 25,\n",
    "                behaviors_list_intersecate = None,\n",
    "                behaviors_list_combine= None,\n",
    "                life_events_list = life_events_list, \n",
    "                industries_list = None, \n",
    "                family_statuses_list = None, \n",
    "                relationship_statuses_list = None, \n",
    "                schools_list = None,\n",
    "                education_statuses_list = education_statuses_list,\n",
    "                majors_list = None,\n",
    "                employers_list = None,\n",
    "                work_positions_list = None,\n",
    "                custom_location=False,\n",
    "                min_population = 120000,\n",
    "                max_population = 550000,\n",
    "                gender_list=gender_list,\n",
    "                country_exclude= None,\n",
    "                regions_list_exclude=None,\n",
    "                cities_list_exclude=None,\n",
    "               )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
